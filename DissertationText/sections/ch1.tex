\documentclass[../dissertation.tex]{subfiles}
 
\begin{document}

\section{General Introduction}

	Categories help us organize the world. They help us predict and hypothesize about category members, helping us quickly select the most appropriate response for each situation. We also rely on language during these processes. As \citet{Lupyan2012} puts it, language augments our thought. For categories, language provides structure in the form of category labels, but language also affects how we think about and even perceive the categories themselves. Thus any thorough investigation of how we learn categories must consider the role of language. \par
	Indeed, many theoretical frameworks of category learning involve language -- some even reference it right in the name. For example, a key theory in perceptual category learning, COVIS, stands for "competition between verbal and implicit systems'" \citep{Ashby1998}. Similarly, a theory put forth by Minda and colleagues is called "A theory of verbal and nonverbal category learning" \citep{Minda2010}. However, to date most theories of category learning that consider language primarily determine whether language has an influence on systems for category learning, rather than further defining the role language plays in these systems.\par
	Thus, the current work seeks to both define a theory of category learning and explore the role language has in this theory. In this review I will synthesize multiple approaches to category learning, all of which have some type of dual-systems model. Following the synthesis, I will review relevant literature that provides suggestions as to how language might be involved in category learning in a dual-systems model. Through these efforts, I will provide a theoretical framework and hypotheses for this dissertation.

\subsection{Dual-systems model for category learning}
	Multiple theories converge on the idea that there are two systems for category learning. In this section, I will first describe a generalized dual-systems model that pulls threads from all of these theories and then go on to describe how each theory fits into the overarching framework. 
	
\subsubsection{Proposed model}
	The proposed model involves two systems for category learning. The first, which I title the \textbf{associative system}, uses associative mechanisms in an iterative manner to learn distributions of features. This system is best suited for learning multidimensional \textit{similarity-based} categories such as natural kinds, where it is difficult to describe necessary and sufficient rules for inclusion. Similarity-based categories have features that are correlated and probabilistic, such that a category instance may not have all of the category-relevant features but tends to have some distribution of them. For example, Manx cats do not have tails, a typical feature of cats, but are still undeniably members of the category \textit{cat}. Thus, the associative system must be able to extract the most frequent pattern of features over many instances in order to learn a category. \par
	The second one is called the \textbf{hypothesis-testing system}. This system uses a more explicit learning method to test and adjust hypotheses about category boundaries. This method relies on selection of relevant features rather than representation of a distribution of feature probabilities. As such, it is most suited for learning rule-based categories, which typically have one or a few easily verbalizable rules for inclusion. For example, the \textit{ad hoc} category \textit{things to be sold at the garage sale} has a simple rule for inclusion that perfectly separates members from non-members. \par
	Thus, we have two systems for category learning, each one ideal for learning a different type of category (similarity-based vs. rule-based). In the upcoming sections, I will describe theoretical and empirical evidence for a dual-systems model from five different approaches to category learning. I will show how each approach informs the current theoretical framework.
\subsubsection{COVIS}
COVIS stands for COmpetition between Verbal and Implicit Systems and is a prominent theoretical framework for perceptual category learning first proposed by \citeauthor{Ashby1998} in 1998. This framework provides a dual-systems model that is grounded in neuropsychological data, allowing it to suggest neurobiological underpinnings for the two systems. It is important to note from the beginning that this framework is mostly concerned with perceptual categories, which are defined as "a collection of similar objects belonging to the same group" \citep[~p. 151]{Ashby2005}. This is in contrast to concepts, which they define as groups of related ideas. Thus, this approach focuses on categorizing objects that can be encountered and perceived in the real world. \par
	As can be inferred from the title, the two category learning systems in COVIS are the \textbf{verbal} and \textbf{implicit} systems. The verbal system is COVIS' answer to our hypothesis-testing system. It is a declarative learning system that uses a hypothesis-testing method to learn category rules, typically for rule-based stimuli. Under COVIS, rule-based stimuli must have inclusion rules that are easy to describe verbally. Typically, rule-based stimuli used by Ashby and colleagues have a single rule for inclusion or two rules combined by "and" or "or."  When a rule-based category involves multiple dimensions, decisions about each dimension are made separately, and these decisions are used to evaluate the logical operators. In other words, each dimension is considered on its own before their combination. These guidelines for rule-based categories ensure that an explicit, verbalizable hypothesis-testing method can be used to learn them. When learning a new category, the verbal system holds candidates for category inclusion rules in working memory, which are tested as stimuli are encountered. Over time, the hypotheses are tested and switched until they reflect the optimal strategy for categorization. \par
	The implicit system from COVIS is most similar to our associative system. Like the associative system, it uses incremental learning to find category boundaries. It is most ideal for learning information-integration categories, which are like similarity-based categories but have also some specific guidelines. Information-integration categories are defined by some combination of dimensions, like some rule-based categories. However, while each dimension can be considered separately in rule-based categories, all dimensions must be considered simultaneously for information-integration categories. Information-integration category membership depends on both the values associated with each dimension as well as the relationship between these values. Information-integration category boundaries are difficult or impossible to describe verbally. COVIS suggests that the implicit system relies on an information stream that connects stimuli, motor responses, and feedback to learn category membership. \par
	One of the most substantial contributions of COVIS is its strong grounding in neurobiology. In the original paper, Ashby and colleagues proposed specific brain regions involved the verbal (hypothesis-testing) and implicit (associative) systems, supported by neuroimaging and patient studies. The verbal (hypothesis-testing) system relies on the prefrontal cortex (PFC), anterior cingulate cortex (ACC), striatum, hippocampus, and the head of the caudate nucleus. Information about the stimuli are processed in fronto-striatial loops and potential category rules are generated. The PFC keeps these rules in working memory while the ACC and the head of the caudate nucleus mediate switching between rules based on feedback. Finally, the hippocampus stores longer-term memory of which rules have already been tested â€“ it is only involved when the task is complex enough that previously tested rules cannot all be stored in working memory \citep{Ashby2005,Ashby2011}. Patient data shows that individuals with frontal damage as well as individuals with Parkison's disease, which affects the basal ganglia including the caudate nucleus, show difficulty in rule-based tasks such as the Wisconsin Cart Sorting Test \citep{Robinson1980} and an experimental rule-based category learning task \citep{Ashby2003b}. This suggests that both frontal regions and the basal ganglia are involved in rule-based categorization. More recent neuroimaging work, however, is still mixed as to the involvement of different areas specifically for rule-based categorization. \citet{Soto2013} found that two separate rule-based tasks could be differentiated based on activation in ventro-lateral PFC, suggesting that specific rules are stored in that region. \citet{Nomura2007} found activation in the medial temporal lobe (MTL), which contains the hippocampus, specifically for rule-based categorization. However, a later study failed to find any activation that was specifically greater for rule-based categorization \citep{Carpenter2016}. Thus, the neural underpinnings of the verbal (hypothesis-testing) system are still under debate. \par
	The implicit (associative) system from COVIS has a different neurobiolgoical pathway for category learning. It uses incremental learning rather than hypothesis testing to learn information-integration (similarity-based) categories. The main structure involved in this procedural learning system is the striatum, which is involved in reinforcement learning with dopamine as the reinforcement signal. From the striatum, information about the category is sent to the thalamus and the globus pallidus, which is within the basal ganglia. From the thalamus, information also runs to motor and premotor cortex. This procedural system links stimuli, motor responses during categorization, and feedback to allow the participant to learn categories. Neuroimaging studies using the implicit system again are mixed, with some finding activation in the caudate body while others fail to find that activation, instead seeing activity in parahippocampal regions \citep{Nomura2007,Carpenter2016}. A separate study also found a role for the putamen in similarity-based category learning \citep{Waldschmidt2011}. \par
	Thus, COVIS provides us with a few key insights. First, it is one of the most studied dual-systems theories of categorization. While Ashby and colleagues generally use visual stimuli for their tasks, this paradigm has been extended to other perceptual domains such as hearing/speech \citep{Chandrasekaran2014, Chandrasekaran2016}. As such, research on the current theoretical framework (associative/hypothesis-testing systems) has much COVIS literature which we can compare it to. It also makes clear claims about the neurobiological basis of the two systems of category learning. While the specifics of these claims are still under debate in the literature, they at least provide regions of interest for researchers who want to conduct neuroimaging research on a dual-systems model of category learning. Finally, this approach is one of the only ones to consider how the two systems interact. \par
	As its name suggests, COVIS also accounts for interactions between the declarative and procedural systems. Behavioral studies encouraging participants to switch between the verbal and implicit systems show that unless participants are cued towards which type of strategy to use on a given trial, they tend to use verbal strategies for all trials \citep{Ashby2010, Erickson2008}. This suggests that use of the verbal system may inhibit use of the implicit system. Indeed, neuroimaging studies and animal models seem to support this interpretation \citep{Foerde2006, Packard1996}. Other research suggests that switching between systems uses the left cerebellum as well as regions involved in the default mode network, including posterior cingulate cortex, medial prefrontal cortex \citep{Turner2017}.
	
\subsubsection{Dimensionality}

Considering categories in terms of their dimensionality is primarily the work of Lupyan and colleagues. Low-dimensional categories are those that cohere on one or a small number of dimensions, such as color, while allowing other dimensions to vary. In this way, low-dimensional categories are similar to rule-based categories, as they can be described using relatively simple rules. In fact, some of Lupyan's papers define low-dimensional categories as those that have a single dimension that can distinguish targets from non-targets \citep{Lupyan2013}. Examples of low-dimensional categories from this study include \textit{things made of wood} and \textit{things with handles}. \par
	In contrast, high-dimensional categories are those that cohere on multiple dimensions, often so many that category rules are difficult to describe. Examples of high-dimensional categories from the previously-mentioned study include \textit{birds}, \textit{tools}, \textit{things that fly}, and \textit{objects that hold water}. Most natural kinds and artifacts are high-dimensional, as well as some \textit{ad hoc} categories. \par
	The core prediction tested using this approach is that low-dimensional categorization should rely more heavily on language than high-dimensional categorization. Similar to the model proposed in this paper, the dimensionality approach postulates that language helps an individual select features, which is a process only helpful for low-dimensional categorization. High-dimensional categorization relies on creating associations across multiple features, which does not involve language as highly. \par 
	To explore this prediction, Lupyan and colleagues interfered with language ability in multiple ways across studies. \citet{Lupyan2013} measured categorization ability in individuals with aphasia for both low- and high-dimensional categories. They found that the individuals with aphasia performed similarly to unimpaired controls on the high-dimensional categories, but showed significantly lower accuracy on the low-dimensional categories. \citet{Lupyan2009} used a concurrent verbal load to reduce the verbal resources available during a categorization task. He found that individuals showed significantly poorer categorization with a verbal load as compared to a visuospatial load specifically for category judgments based on a single dimension (color or size) but not for those based on multiple dimensions (theme). Other studies manipulated language ability by using transcranial direct current stimulation (tDCS). tDCS can raise or lower cortical excitability, depending on the polarity of the stimulation. One study found that cathodal stimulation, which tends to lower excitability, over the left inferior frontal gyrus led to poorer performance on low-dimensional but not high-dimensional categorization \citep{Lupyan2012b}. Another study used stimuli that could either be categorized using a uni-dimenional or a bi-dimensional strategy. Cathodal tDCS over Wernicke's area made participants more likely to chose the bi-dimensional strategy, indicating that interfering with language functioning resulted in participants using higher-dimensional categorization \citep{Perry2014}. \par 
	The dimensionality approach to category learning and the studies done to test it provide multi-method evidence for the role of language in low-dimensional categorization. Unlike COVIS, where the verbal system largely uses language to describe and rehearse candidate category rules, the dimensionality approach states that language is used to select relevant features for a category. This idea has highly influenced this paper's dual-systems model, in which the hypothesis-testing system does select category-relevant features. However, the evidence for this approach is largely unable to speak for the system underlying high-dimensional categorization, as most of the effects for this system are null. Thus, it is not clear from this approach whether the hypothesized broad inter-item association building is in fact how individuals learn high-dimensional categories.
\subsubsection{Statistical Density}
\subsubsection{Verbal/nonverbal}
\subsubsection{Taxonomic/thematic}

 
\subsection{Vocabulary/labels and category learning}

\subsection{Executive function and category learning}

\end{document}

