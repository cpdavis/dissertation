---
title: "Category Learning Pilot"
author: "Kayleigh Ryherd"
date: "11/6/2017"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(reshape)
library(nlme)
setwd("~/dissertation/CatLearningfMRI/OrderPilot")
data <- read.csv("MergeExport.csv")
data <- data[data$Session == 1,]
rel.data <- data[,c(2,17,23,32,35,44,47,59,62,71,74)]

ds <- rel.data[!is.na(rel.data$DSTestStim.ACC),]
du <- rel.data[!is.na(rel.data$DUTestStim.ACC),]
ss <- rel.data[!is.na(rel.data$SSTestStim.ACC),]
su <- rel.data[!is.na(rel.data$SUTestStim.ACC),]

modifyList <- list(ds, du, ss, su)
names(modifyList) <- c("ds", "du", "ss", "su")

for (i in 1:length(modifyList)) {
modifyList[[i]] <- modifyList[[i]][,colSums(modifyList[[i]], na.rm = TRUE) != 0]
names(modifyList[[i]]) <- c("Subject", "Block", "Trial", "ACC", "RT")
modifyList[[i]] <- modifyList[[i]][modifyList[[i]]$Subject != 666,]
modifyList[[i]]$type <- names(modifyList[i])
}


list2env(modifyList, envir=.GlobalEnv)

all <- rbind(ds,du,ss,su)

ordervals <- read.csv("Order.csv")
all.merge <- merge(all, ordervals, by = "Subject")

all.nd <- all.merge[!duplicated(all.merge[,c(1,3,6)]),]

pd.acc <- data.frame(tapply(all.nd$ACC, list(all.nd$Subject, all.nd$type), mean, na.rm = TRUE))
pd.acc2 <- melt.data.frame(pd.acc)
names(pd.acc2) <- c("Condition", "ACC")

pd.acc3 <- data.frame(tapply(all.nd$ACC, list(all.nd$Subject, all.nd$Block), mean, na.rm = TRUE))
pd.acc3$Subject <- rownames(pd.acc3)
pd.acc4 <- melt.data.frame(pd.acc3)
names(pd.acc4) <- c("Subject", "Block", "ACC")


pd.rt <- data.frame(tapply(all.nd$RT, list(all.nd$Subject, all.nd$type), mean, na.rm = TRUE))
pd.rt2 <- melt.data.frame(pd.rt)
names(pd.rt2) <- c("Condition", "RT")
```

```{r}
p1 <- ggplot(pd.acc2, aes(Condition, ACC)) + geom_violin()
p1

p1 <- ggplot(pd.acc4, aes(Block, ACC, group = Subject, color = Subject)) + geom_point() + geom_line()
p1

p1 <- ggplot(pd.rt2, aes(Condition, RT)) + geom_violin()
p1
```

```{r}
all.nd$Block <- as.factor(all.nd$Block)
m1 <- lme(ACC ~ Block, random = ~1|Subject, data = all.nd)
summary(m1)
anova(m1)

m1 <- lme(RT ~ Block, random = ~1|Subject, data = all.nd)
summary(m1)
anova(m1)

volumeVars = names(ordervals[-1])
models = lapply(volumeVars, function(x) { lme( eval(substitute(ACC ~  i, list(i=as.name(x)) )), random = ~1|Subject, data=all.nd)})
lapply(models, function(y) {anova(y)})

volumeVars = names(ordervals[-1])
models = lapply(volumeVars, function(x) { lme( eval(substitute(RT ~  i, list(i=as.name(x)) )), random = ~1|Subject, data=all.nd)})
lapply(models, function(y) {anova(y)})


```

Only UnsupervisedOrder is significant. Let's look at it.

```{r}
us.only <- all.nd[all.nd$type == "du" | all.nd$type == "su",]

p1 <- ggplot(us.only, aes(UnsupervisedOrder, ACC)) + geom_violin() + facet_grid(.~type)
p1

m1 <- lme(ACC ~ UnsupervisedOrder*type, random = ~1|Subject, data = us.only)
summary(m1)
```

So, it looks like getting dense first in the unsupervised training helps you perform better on sparse-unsupervised.

Thus, this pilot data combined with prior research suggests that the ideal order is:

1. SparseUnsupervised
2. DenseUnsupervised
3. SparseSupervised or DenseSupervised -- no effect either way

